{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55178cf5-13bd-460e-bd1c-b2b4bb1d6672",
   "metadata": {},
   "source": [
    "# Credit Risk Classification report\n",
    "---\n",
    "## Overview of the Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c09562-0548-4a47-94f6-ca086cfcbb89",
   "metadata": {},
   "source": [
    "### Purpose of the analysis\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a36894-bc72-4cad-b2f2-609b22e51e12",
   "metadata": {},
   "source": [
    "For this analysis, we were given a dataset composed of 8 columns and 77536 rows holding information about credit borrowers and we were\n",
    "tasked with predicting their credit worthiness or the outcome of each loan application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436c4934-e45a-4246-841e-21579ebdc124",
   "metadata": {},
   "source": [
    "### Methodology\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1197f506-0aec-4aea-aa07-84e52cd7f01c",
   "metadata": {},
   "source": [
    "- We started off  by reading the `lending_data.csv` into a pandas dataframe and acknowledged the existence of the following columns in the\n",
    "dataset.['loan_size','interest_rate','borrower_income','debt_to_income','num_of_accounts','derogatory_marks\t','total_debt','loan_status'].\n",
    "\n",
    "- With that information , the next step was to predict the 'loan_status' for each applicant based on the following criterias. \n",
    "['loan_size','interest_rate','borrower_income','debt_to_income','num_of_accounts','derogatory_marks','total_debt'].\n",
    "Therefore the outcome 'loan_status' column became our label whereas the criterias columns were used as features.\n",
    "\n",
    "- Then We separated both components of the dataframe and stored them in sapare variables , y for the labels anf X for the features.\n",
    "\n",
    "- Furthermore , we used the function `train_test_split` imported from the `sklearn.model_seletion` library to split each component of\n",
    "the data into 2 buckets. 'X_train' , 'X_test' , 'y_train' and 'y_test' at a random state of 1.\n",
    "\n",
    "- Then ,using the LogisticRegression algorithm imported from `sklearn.linear_model`, we instantiated a `logistic regression model` with the random_state of 1 and solver `lbfgs`which is a popular optimization algorithm , very efficient for handling large datasets and dealing with many parameters as we did in this case study.\n",
    "\n",
    "- Finally , we fitted the model using the 'X_train' and the 'y_train' and made some predictions using the X_test splitted data ,then evaluated the model performance by generating a confusion matrix and printing a classification report using the `classification_report`  imported from the sklearn.metrics library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce3ef47-4553-4292-b443-637d1a71022e",
   "metadata": {},
   "source": [
    "Ultimately, we aimed to determine whether the combination of features for each applicant scored a `0`or`1`  , effectively solving the equation y = aX+b where y=1 translated as (high-risk loan)application and\n",
    "y = 0 translated as (healthy loan) application.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143f233b-19aa-4377-9d8e-6b574f349341",
   "metadata": {},
   "source": [
    "\n",
    "## Results\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d388c18-668f-460f-89f9-b2b3b3ce5847",
   "metadata": {},
   "source": [
    "Our dataset had 77536 rows. \n",
    "\n",
    "- The confusion matrix returned an array of 19384 values ,representing about a quater of our dataset used to test the data.\n",
    "- On the confusion matrix , we are looking at how many times the model predicted 0 where 0 was due , 1 where 1 was due and also \n",
    "the number of times it confused the 0 for 1 and vice versa.We can see that it predicted 'healthy loan' correctly 18663 correctly and 'high risk loan' correctly  563 times out of the 19384 times it ran through the testing dataset, leaving a margin of error of just 158 accross both components.This means that the accuracy of the model prediction sit at a whooping 99%.\n",
    "- For the `Healthy Loans` (0), the precision is 1.00, indicating that all the instances for this label were correctly identified . The recall is 0.99, meaning that 99% of the instances of this label were correctly classified.\n",
    "- For the `High-Risk Loan` (1) the precision is 0.85, indicating that 85% of instances for this label were accurately identified. The recall is 0.91, indicating that 91% of the instances of this label were correctly classified.\n",
    "- This is a very high score for our model ,but a closer look at the data distribution accross both components shows that out of the 19384 values in our test data , 18765 represented the total of`healthy loan` applications versus '619' representing the `high risk loan` application .This, in addition to the lower precision score on the `high-risk loan`means that we trained our model to recognised mostly healthy loan  which signals a  bias in our analysis ,because even if the model somehow marked 0 all the way down, it would have still scored a whooping  97% which represents the percentage of 'healthy loan' fed to our model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94990c8a-5caa-40e3-88bd-b8e38bbc258a",
   "metadata": {},
   "source": [
    "## Summary\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919a0d78-fbf8-4116-b861-302a62ffb707",
   "metadata": {},
   "source": [
    "Overall I would say that Supervised Learning Algorithms in general do a great job at predicting data ,but as for this case study ,\n",
    "the risk of bias that comes with human input makes it subjective at times. That's the reason why i think ,for total transparency \n",
    "using Unsupervised Machine Learning algorithm like the kmeans or Birch models is preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0168d147-7832-4922-aa4f-93cbad4e971c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
